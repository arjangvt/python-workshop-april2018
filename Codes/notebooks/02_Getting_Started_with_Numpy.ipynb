{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Programming, Data Visualization, & Model Fitting with Python\n",
    "\n",
    "# - Numpy Fundamentals\n",
    "\n",
    "#### Developed by:  A. Fahim and B. Vegetabile, University of California, Irvine\n",
    "\n",
    "This notebook is a supplement to the workshop \"Introduction to Programming, Data Visualization, & Model Fitting with Python\"\n",
    "\n",
    "# Getting Started\n",
    "\n",
    "Import `numpy` as `np` to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was mentioned earlier, any package should be brought in with an identifer like the one above.  \n",
    "\n",
    "# Comparing Python Lists with Numpy Arrays\n",
    "\n",
    "Let's start to disect why we want to actually be using numpy arrays in the first place.  Consider the following list of numbers\n",
    "```python\n",
    "vect_a = [ 0.40596906,  1.03987797, -0.74112064, -1.81293637,  0.12438781,\n",
    "           0.97333303, -1.56900792, -0.41787639, -0.15112056, -0.46346588]\n",
    "```\n",
    "\n",
    "We can use the `dir()` command to see that we can append to this list, count it, extend it, insert into it, pop values from it, remove indices, sort or reverse it.  Additionally, if we want to know how many items are in the list we can use the `len` function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These don't seem like useful commands for performing say matrix algebra though.  Additionally if we embed a list inside another list, we get the same operations...\n",
    "\n",
    "```python\n",
    "mat_a = [[0.40596906,  1.03987797, -0.74112064, -1.81293637,  0.12438781],\n",
    "         [0.97333303, -1.56900792, -0.41787639, -0.15112056, -0.46346588]]\n",
    "```\n",
    "\n",
    "```\n",
    "mat_a.append   mat_a.extend   mat_a.insert   mat_a.remove   mat_a.sort     \n",
    "mat_a.count    mat_a.index    mat_a.pop      mat_a.reverse  \n",
    "```\n",
    "\n",
    "Using the length operation on this returns 2, which clearly is not what we would expect.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting to Numpy Arrays\n",
    "\n",
    "Let's convert these to numpy arrays and see the list of things that are available to us. \n",
    "\n",
    "```python\n",
    "vect_b = np.array(vect_a)\n",
    "mat_b = np.array(vect_b)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typing `mat.<tab>` shows us a much larger list of things that we can do with a `numpy` array.  \n",
    "\n",
    "```\n",
    "mat_b.T             mat_b.copy          mat_b.imag          mat_b.ravel         mat_b.sum\n",
    "mat_b.all           mat_b.ctypes        mat_b.item          mat_b.real          mat_b.swapaxes\n",
    "mat_b.any           mat_b.cumprod       mat_b.itemset       mat_b.repeat        mat_b.take\n",
    "mat_b.argmax        mat_b.cumsum        mat_b.itemsize      mat_b.reshape       mat_b.tobytes\n",
    "mat_b.argmin        mat_b.data          mat_b.max           mat_b.resize        mat_b.tofile\n",
    "mat_b.argpartition  mat_b.diagonal      mat_b.mean          mat_b.round         mat_b.tolist\n",
    "mat_b.argsort       mat_b.dot           mat_b.min           mat_b.searchsorted  mat_b.tostring\n",
    "mat_b.astype        mat_b.dtype         mat_b.nbytes        mat_b.setfield      mat_b.trace\n",
    "mat_b.base          mat_b.dump          mat_b.ndim          mat_b.setflags      mat_b.transpose\n",
    "mat_b.byteswap      mat_b.dumps         mat_b.newbyteorder  mat_b.shape         mat_b.var\n",
    "mat_b.choose        mat_b.fill          mat_b.nonzero       mat_b.size          mat_b.view\n",
    "mat_b.clip          mat_b.flags         mat_b.partition     mat_b.sort          \n",
    "mat_b.compress      mat_b.flat          mat_b.prod          mat_b.squeeze       \n",
    "mat_b.conj          mat_b.flatten       mat_b.ptp           mat_b.std           \n",
    "mat_b.conjugate     mat_b.getfield      mat_b.put           mat_b.strides       \n",
    "```\n",
    "\n",
    "Operations like ```cumsum``` and `size` are more in line with what we will want to do with matrix operations for data science.  \n",
    "\n",
    "###### Mini Exercise\n",
    "\n",
    "For the object `mat_b`, calculate the row sums and column sums for this object.  Now attempt to write a small loop for `mat_a` and compare the amount of code that you used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra with Numpy\n",
    "\n",
    "Another great feature of `numpy` is that it is incredibly useful for performing matrix operations.  \n",
    "\n",
    "Consider the two matrices.\n",
    "\n",
    "```python\n",
    "mat_A = np.array([[1, 4],\n",
    "                  [3, 5]])\n",
    "mat_B = np.array([[12, 14, 34],\n",
    "                  [1, 3, 5]])\n",
    "vect_x = np.array([1,2])\n",
    "```\n",
    "\n",
    "Copy and paste below the code and run it.  We'll be using the matrix $A$ and $B$ and the vector $x$ for some examples of matrix manipulations with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "\n",
    "There is a slight oddity to matrix multiplication in python, but once you get used to the syntax it becomes very easy.  The function from numpy for matrix multiplication is called `dot`.  \n",
    "\n",
    "Therefore to multiply to matrices use\n",
    "\n",
    "```python\n",
    "np.dot(A, B)\n",
    "```\n",
    "\n",
    "where `A` and `B` are of appropriate dimensions.  Additionally, there is another notation which is similar and often times more easy to use.\n",
    "\n",
    "```python\n",
    "A.dot(B)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implies that the array `A` has method `dot` which can be applied to matrix `B` if it is of appropriate dimension.  This chaining together of commands can be very useful.\n",
    "\n",
    "Attempting to do matrix muplication in following \n",
    "\n",
    "```python\n",
    "A * B\n",
    "```\n",
    "will attempt to perform element-wise multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Small exercise.  \n",
    "\n",
    "Play with the matrix multiplication commands.  The multiplication $AB$ should work, while $BA$ should give and error.  Attempt to multiply the vector $x$ times matrix $A$ with both matrix and elementwise multiplication and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensions of numpy arrays\n",
    "\n",
    "Run the code below to see how numpy provides the dimension of a one dimensional array. Compare that with the shape of the two dimensional array below it. \n",
    "\n",
    "```python \n",
    "simple_array = np.array([1,2,3])\n",
    "two_dimensional = np.array([[1,2],[3,4]])\n",
    "print simple_array.shape\n",
    "print two_dimensional.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that a single value of within a tuple is returned.  Most of the time this is okay, as we say with the matrix multiplication, python knows that this should truly be a column vector or a row vector and adds a dimension for us.  \n",
    "\n",
    "Where this becomes an issue is when trying to merge arrays together into a matrix.  Consider the two vectors which we would like to merge together as columns of a matrix,\n",
    "\n",
    "```python\n",
    "col1 = np.array([1,2,3])\n",
    "col2 = np.array([4,5,6])\n",
    "```\n",
    "\n",
    "Numpy provices the following commands for join arrays together\n",
    "\n",
    "```python\n",
    "np.hstack([array1, array2, ...])\n",
    "np.vstack([array1, array2, ...])\n",
    "```\n",
    "\n",
    "Let's see what happens when use these on `col1` and `col2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could simply transpose this to get the matrix we want, but there is another way.  That is adding a `newaxis` to the matrix.  This can be done as follows:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "col1_vect = col1[:, np.newaxis]\n",
    "col2_vect = col2[:, np.newaxis]\n",
    "\n",
    "print np.vstack([col1_vect, col2_vect])\n",
    "print np.hstack([col1_vect, col2_vect])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively if we know the true dimension, this can be done by using the reshape command to give the desired behavior as well. The `np.newaxis` command is often more advantageous since we don't how to know the number of elements of the array beforehand.\n",
    "\n",
    "```\n",
    "col1.reshape(3,1)\n",
    "```\n",
    "\n",
    "Manipulating one-dimensional arrays in Python is often handy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy.linalg Functions\n",
    "\n",
    "Numpy additionally has a bunch of functions that are accesible through typing `np.linalg.<tab>`\n",
    "\n",
    "```python\n",
    "np.linalg.LinAlgError      np.linalg.eig              np.linalg.lstsq            np.linalg.slogdet\n",
    "np.linalg.Tester           np.linalg.eigh             np.linalg.matrix_power     np.linalg.solve\n",
    "np.linalg.absolute_import  np.linalg.eigvals          np.linalg.matrix_rank      np.linalg.svd\n",
    "np.linalg.bench            np.linalg.eigvalsh         np.linalg.multi_dot        np.linalg.tensorinv\n",
    "np.linalg.cholesky         np.linalg.info             np.linalg.norm             np.linalg.tensorsolve\n",
    "np.linalg.cond             np.linalg.inv              np.linalg.pinv             np.linalg.test\n",
    "np.linalg.det              np.linalg.lapack_lite      np.linalg.print_function   \n",
    "np.linalg.division         np.linalg.linalg           np.linalg.qr                         \n",
    "```\n",
    "\n",
    "Often you will find yourself pounding your fist on the desk forgeting to type `linalg` after `np` trying to invert a matrix.\n",
    "\n",
    "\n",
    "# Random Numbers in Numpy\n",
    "\n",
    "As data scientists another set of functions that are incredibly useful are random number generators in a few libraries in python.  \n",
    "\n",
    "Standard python provides the `random` library.  \n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "random.BPF              random.WichmannHill     random.getstate         random.sample\n",
    "random.LOG4             random.betavariate      random.jumpahead        random.seed\n",
    "random.NV_MAGICCONST    random.choice           random.lognormvariate   random.setstate\n",
    "random.RECIP_BPF        random.division         random.normalvariate    random.shuffle\n",
    "random.Random           random.expovariate      random.paretovariate    random.triangular\n",
    "random.SG_MAGICCONST    random.gammavariate     random.randint          random.uniform\n",
    "random.SystemRandom     random.gauss            random.random           random.vonmisesvariate\n",
    "random.TWOPI            random.getrandbits      random.randrange        random.weibullvariate\n",
    "\n",
    "\n",
    "help(random.normalvariate)\n",
    "\n",
    "Help on method normalvariate in module random:\n",
    "\n",
    "normalvariate(self, mu, sigma) method of random.Random instance\n",
    "    Normal distribution.\n",
    "    \n",
    "    mu is the mean, and sigma is the standard deviation.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the random library mainly returns a single value from the functions.  For simulations we may be interested in generating lots and lots of random variables.  The `numpy` random number functions are more useful for that.  \n",
    "\n",
    "Type `np.random.<tab>` and you will see the following list of functions.\n",
    "\n",
    "```python\n",
    "np.random.Lock                  np.random.logistic              np.random.random_integers\n",
    "np.random.RandomState           np.random.lognormal             np.random.random_sample\n",
    "np.random.Tester                np.random.logseries             np.random.ranf\n",
    "np.random.absolute_import       np.random.mtrand                np.random.rayleigh\n",
    "np.random.bench                 np.random.multinomial           np.random.sample\n",
    "np.random.beta                  np.random.multivariate_normal   np.random.seed\n",
    "np.random.binomial              np.random.negative_binomial     np.random.set_state\n",
    "np.random.bytes                 np.random.noncentral_chisquare  np.random.shuffle\n",
    "np.random.chisquare             np.random.noncentral_f          np.random.standard_cauchy\n",
    "np.random.choice                np.random.normal                np.random.standard_exponential\n",
    "np.random.dirichlet             np.random.np                    np.random.standard_gamma\n",
    "np.random.division              np.random.operator              np.random.standard_normal\n",
    "np.random.exponential           np.random.pareto                np.random.standard_t\n",
    "np.random.f                     np.random.permutation           np.random.test\n",
    "np.random.gamma                 np.random.poisson               np.random.triangular\n",
    "np.random.geometric             np.random.power                 np.random.uniform\n",
    "np.random.get_state             np.random.print_function        np.random.vonmises\n",
    "np.random.gumbel                np.random.rand                  np.random.wald\n",
    "np.random.hypergeometric        np.random.randint               np.random.warnings\n",
    "np.random.info                  np.random.randn                 np.random.weibull\n",
    "np.random.laplace               np.random.random                np.random.zipf\n",
    "```\n",
    "\n",
    "Let's consider the random `normal` function and the `seed` functions.\n",
    "\n",
    "First to generate random normal values, we see the format of the function from `numpy: `\n",
    "\n",
    "```python\n",
    "np.random.normal(loc=0.0, scale=1.0, size=None)\n",
    "```\n",
    "\n",
    "Compared with the `random.normalvariate` we see that we have a size component.  Now turning to the `seed` function, we can use this so that we always obtain the same results each time we run a simulation.  \n",
    "\n",
    "##### Mini Exercise\n",
    "\n",
    "Generate 100 values from a random normal distribution with mean $\\mu=3$ and variance $\\sigma^2 =1$.  Then use the functions provided by numpy arrays to calculate the following statistics: mean, var, min, max.  This exercise allows to you generate some random numbers and begin computing simple statistics on them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Simulation, Matrix Manipulation and Linear Regression\n",
    "\n",
    "Let's combine the simple python expressions learned earlier combined with what we've learned with numpy arrays to create a function that does linear regression.  \n",
    "\n",
    "Consider the simple model for $i = 1, \\dots, N$ \n",
    "\n",
    "\\begin{equation*}\n",
    "    Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i\n",
    "\\end{equation*}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\epsilon_i \\sim N(0, 1)\n",
    "\\end{equation*}\n",
    "\n",
    "If we construct our observations such that they are in the following matrix form,\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{Y} = \\left( \\begin{array}{ccc}\n",
    "Y_1 \\\\\n",
    "Y_2 \\\\\n",
    "\\vdots \\\\\n",
    "Y_i \\\\\n",
    "\\vdots \\\\\n",
    "Y_N\n",
    "\\end{array} \\right)\n",
    "\\qquad\n",
    "\\mathbf{X} = \\left( \\begin{array}{cc}\n",
    "1 & x_{1} \\\\\n",
    "1 & x_{2} \\\\\n",
    "\\vdots & \\vdots  \\\\\n",
    "1 & x_{i} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "1 & x_{N} \\\\\n",
    "\\end{array} \\right)\n",
    "\\qquad\n",
    "\\beta = \\left( \\begin{array}{ccc}\n",
    "\\beta_0 \\\\\n",
    "\\beta_1 \\\\\n",
    "\\end{array} \\right)\n",
    "\\end{equation*}\n",
    "\n",
    "It can be shown that the solution that minimizes mean squared error loss, (i.e. $\\arg\\min_{\\beta }\\frac{1}{N}\\sum_{i = 1}^{N} (Y_i - X_i^T\\beta)^2$) is,\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat \\beta = (X^T X)^{-1} (X^T Y)\n",
    "\\end{equation*}\n",
    "\n",
    "To see how this works let's simulate values.\n",
    "\n",
    " - 1) Create variables `beta0` and `beta1` such that $\\beta_0 = 5$ and $\\beta_1 = 1$\n",
    " - 2) Create an array of observations `X` of size 1000, such that $X_i \\sim N(0, 1)$.\n",
    " - 3) Create an array of `noise` of size 1000, such that $\\epsilon_i \\sim N(0,1)$.  \n",
    " - 4) Generate the response array `Y` such that `Y = \\beta_0 + \\beta_1 * X + noise`\n",
    " - 5) Create a design matrix `X_design` (the bold faced matrix above) such that \n",
    " \n",
    " ```python\n",
    " ones_vector = np.ones(1000)\n",
    " X_design = np.vstack([ones_vector, X]).T\n",
    " print X_design\n",
    " ```\n",
    " \n",
    " - 6) Use the design matrix and the vector `Y` to find $\\hat\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We inherently already are able to test our skills with linear algebra by setting up our simulation. An alternative way to test this is to use the `np.linalg.lstsq` function.  Use the `help(np.linalg.lstsq)` to see how this function works and what it returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
